Источник данных: размеченные данные о "токсичности" комментариев пользователей.

Стек: Pandas, NumPy, Re, NLTK, sklearn, LightGBM, предобработка данных, исследовательский анализ данных, визуализация, logistic regression, decision tree, random forest.

Цель проекта: Разработать модель, классифицирующую (бинарная классификация) комментарии на "токсичные" и "позитивные".

Целевая метрика: f1_score > 0.75 \
Полученное значение: f1_score = 0.775

Состав проекта:
- Предобработка и первичный анализ данных
- Подготовка (лемматизация) данных
- Обучение и валидация модели
- Балансировка классов
- Тестирование модели
- Выводы
