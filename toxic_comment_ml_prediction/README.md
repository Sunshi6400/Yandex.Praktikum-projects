**Источник данных:** размеченные данные о "токсичности" комментариев пользователей.

**Стек:** Pandas, NumPy, Re, NLTK, sklearn, LightGBM, предобработка данных, исследовательский анализ данных, визуализация, logistic regression, decision tree, random forest.

**Цель проекта:** Разработать модель, классифицирующую (бинарная классификация) комментарии на "токсичные" и "позитивные".

**Целевая метрика:** f1_score > 0.75

**Состав проекта:**
- Предобработка и первичный анализ данных
- Подготовка (лемматизация) данных
- Обучение и валидация модели
- Балансировка классов
- Тестирование модели
- Выводы

**Полученные результаты:**
- проведено сравнение 6 сочетаний моделей ML (логистической регрессии и градиентного бустинга), различных способов балансировки классов и числа итераций;
- Наибольшая точность прогнозирования получено для модели логистической регрессии с регуляризацией:
  - f1_score = 0.775
- предложены возможные пути дальнейшего повышения качества исходных данных с целью повышения точности прогнозирования. 
