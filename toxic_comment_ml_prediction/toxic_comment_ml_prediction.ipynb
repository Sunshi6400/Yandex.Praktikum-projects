{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка модели классификации комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформулируем цель проекта, определимся с задачей и приступим к анализу данных.\n",
    "\n",
    "### Цель проекта:\n",
    "Разработать модель машинного обучения, классифицирующую комментарии на \"токсичные\" и \"позитивные\".\n",
    "\n",
    "Метрика - f1-score.\n",
    "\n",
    "Перед нами задача классификации (не регрессии)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Предобработка и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на имеющиеся в нашем распоряжении данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "comment_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оу. Перед нами (мной) ИНОСТРАННЫЙ (для меня) язык. Интересно. \n",
    "\n",
    "Почти 160 тысяч размеченных комментариев. NAN-пропусков нет. Сходу не видно \"токсичных комментариев\". Оттого и не ясно, например, каково соотношение классов и какой, при необходимости, стоит делать \"перевес\" в пользу одного из классов. Посмотрим на это.\n",
    "\n",
    "Из \"не нужного\" вижу знаки переноса строки (это которые \\n) + некий набор двоеточий (::::). Что он может значит - не знаю, однако, сомневаюсь, что мне вообще нужно об этом узнавать. Чистить, скорее всего, будем предметно - удаляя описанные артефакты (конечно не в ручную). \n",
    "\n",
    "Но сперва - баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90 на 10. А я всегда говорил - \"Люди - хорошие!\"\n",
    "\n",
    "Стало быть дисбаланс классов налицо - следовательно, будем готовы применить МЕТОДЫ. Какие именно я сейчас не помню, но когда ПРИДЁТ ВРЕМЯ, я всё резко вспомню и \"распишу в лучшем виде\" (да, сегодня в комментариях к проекту - много комментариев к комментариям, смиритесь. И в очередной раз - СПАСИБО за то, что вы делаете. Вы очень крутые и занимаетесь важным делом - учите людей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспоминая работу с категориальными признаками, \"опустим\" все буквы в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_data['text'] = comment_data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим несколько случайных комментариев из \"тела\" датасета + \"хвост\", что бы понять, с чем нам ещё (теоретически) предстоит работать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\n socialistm? \\n\\nthere are two important features of smith\\'s concept of the \"\"invisible hand\"\". first, smith was not advocating a social policy (that people should act in their own self interest), but rather was describing an observed economic reality (that people do act in their own interest). second, smith was not claiming that all self-interest has beneficial effects on the community. he did not argue that self-interest is always good; he merely argued against the view that self-interest is necessarily bad. it is worth noting that, upon his death, smith left much of his personal wealth to charity.\\n\\ngood!  let\\'s all make sure we put forth the idea that adam smith was a socialist.  that\\'s the wikipedia way!\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data.loc[150, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий \"косяк\" (косяк ли это?) - наличие в теле комментариев \"особенной\" разметки для апострофов- вместе с обраным слешем. Думаю здесь нам потребуется замена \\' на \"чистый апостроф\". С другой стороны, ведь под каждым апострофом в английском языке (ну почти под каждым) скрывается слово - глаголы типа is, are, am и тому подобное. Следовательно, мы, теоретически, можем \"раскрывать\" апострофы в виде дополнительного слова. Да, звучит СЛОЖНО (только потому, что я не знаю методов, которыми это можно сделать БЫСТРО) и НЕОЧЕВИДНО. Но не будем отметать такой вариант.\n",
    "\n",
    "Следующий!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there is no evidence that this block has anything to do with sock accounts. my use of my accounts was completely legitimate. and contrary to what rodhullandemu is trying to imply, the only accounts that i used in the police talk page are mr3003nights and this one (which is a completely legitimate practice). i was blocked for a discussion in the talk page of the article on the policenot for editing the actual article. please read that discussion i linked to and see it for yourself that it was pure unjustified retaliation for offering evidence rodhullandemu could not answer http://en.wikipedia.org/wiki/talk:police#why_reiterate_.22reduce_civil_disorder.22_instead_of_protection_of_property.3f 69.228.251.134'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data.loc[1500, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В наличии ссылка на википедию + IP адрес. Зачем они здесь? Автор, наверняка, так выстраивал \"линию защиты\" или обвинения. Нам же это, скорее всего, не поможет, т.к. ссылка будет воспринята как одно ОГРОМНОЕ слово и, скорее, помешает обучению модели, чем поможет. Хотя это не точно. И тем не менее, БУДЕМ УДАЛЯТЬ. Ссылки, как правило, начинаются на http(s) и идут НЕПРЕРЫВНО. Следовательно, мы можем РАСЧИСТИТЬ датасет удаляя все ДЛИННЫЕ слова, начинающиеся с http. \n",
    "\n",
    "Что делать с ip пока не понятно. Высок риск потерять комментарии с ценами и прочим. Ведь у нас магазин. И писать цены и сравнение в комменты - вполне обыденная практика. С другой стороны, наличие цифр в модели, врядли поможет отсортировать комментарии на положительные и токсичные. Ведь никого не обижает цифра 8. Или кого-то обижает? Так или иначе, если из предложения \"У тебя мозги как у 8-летнего школьника\" убрать цифру 8, смысл сохранится. Следовательно, цифры нам, скорее не нужны, чем нужны. Уберем.\n",
    "\n",
    "Next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingrid tamuyeye is also a young athlete but does not wish her name to be published on the interner and daniella ashaju is one of the best spokes people of youngsters but does not want her name to be published.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data.loc[15000, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё в порядке. Всем бы так."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nthe addition was a \"\"wikipedia situation where a fair use image shouldn\\'t be used\"\", not a \"\"counterexample showing what fair-use is not\"\", as the section is. \"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data.loc[150000, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде бы тоже всё норм, только мне не нравится куча кавычек. Да, я сам ОБОЖАЮ ими пользоваться - чтобы уточнить смысл. Но, полагаю, модели ML на это будет плевать. По крайней мере в том виде, в каком я её себе сейчас представляю. Стало быть кавычки - тоже под нож."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, перечень \"артефактов\" для предобработки данных:\n",
    "- \\n\n",
    "- :::: (думаю, тут можно удалить все двоеточия по тексту. Особо смысл от этого не потеряется, мне кажется)\n",
    "- \\' -> ' (замена каким-то образом апострофо-слешей на апострофы).\n",
    "- http... (ссылки)\n",
    "- Цифры\n",
    "- \"\"\"\"\"\"\" (вагоны кавычек. Убираем всё)\n",
    "\n",
    "Для модели того типа, который я сейчас себе представляю, данные не должны содержать ничего, кроме слов. Ни знаков препинания (да, можно и с ними, но я сейчас не особо понимаю, как сохранить нужные з.п. и удалить не нужные з.п.), ни цифр, ни ссылок, ни апострофов и т.д.\n",
    "\n",
    ">UPD. Тут ещё подумал, что так же, в принципе, смысла не имеют никнеймы пользователей в комментариях. Но как их всех отследить, я пока не представляю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поехали!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нам нужно оставить в тексте? В принципе, только буквы. Однако, сначала нам нужно удалить ссылки http, что бы в строках, после удаления НЕ-букв, не остались разорванные на куски ссылки, которые будут совершенно бесполезны и даже вредны при обучении модели и подготовке данных. \n",
    "\n",
    "Воспользуемся re.\n",
    "\n",
    "> Разобраться в том, как работают регулярки было не особо сложно. Пользовался https://regex101.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 365 ms, sys: 262 µs, total: 365 ms\n",
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "def re_sub_http(string):\n",
    "    pattern_http = 'http.*\\s'\n",
    "    return re.sub(pattern_http, ' ', string)\n",
    "\n",
    "comment_data['text'] = comment_data['text'].apply(re_sub_http)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь убираем символ переноса на другую строку. \n",
    "\n",
    "Я не разобрался, как удалить этот символ из строк с помощью регулярок - вероятно потому, что \\n является встроенным оператором библиотеки. Поэтому воспользуюсь встроенным \"реплейсом\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\n socialistm? \\n\\nthere are two important features of smith\\'s concept of the \"\"invisible hand\"\". first, smith was not advocating a social policy (that people should act in their own self interest), but rather was describing an observed economic reality (that people do act in their own interest). second, smith was not claiming that all self-interest has beneficial effects on the community. he did not argue that self-interest is always good; he merely argued against the view that self-interest is necessarily bad. it is worth noting that, upon his death, smith left much of his personal wealth to charity.\\n\\ngood!  let\\'s all make sure we put forth the idea that adam smith was a socialist.  that\\'s the wikipedia way!\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data['text'] = comment_data['text'].replace('/n', ' ')\n",
    "comment_data.loc[150, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, очистим данные от всего, кроме букв. Маленьких - большие мы все уже \"съели\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_sub_letters(string):\n",
    "    return re.sub(r'[^a-z ]', ' ', string)\n",
    "\n",
    "comment_data['text'] = comment_data['text'].apply(re_sub_letters)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there is no evidence that this block has anything to do with sock accounts  my use of my accounts was completely legitimate  and contrary to what rodhullandemu is trying to imply  the only accounts that i used in the police talk page are mr    nights and this one  which is a completely legitimate practice   i was blocked for a discussion in the talk page of the article on the policenot for editing the actual article  please read that discussion i linked to and see it for yourself that it was pure unjustified retaliation for offering evidence rodhullandemu could not answer                '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data.loc[1500, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, теперь перед нами есть текст с кучей пробелов, однако, в процессе разделения всё встанет на свои места и ненужные пробелы будут \"ликвидированы\". Да, мы можем их устранить несколько раз прогнав замену \"  \" на \" \" (двойной пробел на пробел), однако, зачем? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальнейшее движение возможно в 2 направлениях - в сторону стемминга и лемматизации. Логически, лемматизация \"лучше\", т.к. позволяет почти наверняка получить более \"точные\" слова, а значит меньшее число и большее качество признаков для обучения модели. Тем не менее, стемминг работает быстрее и, в нашем случае, почти наверняка только он сможет справить с задачей в \"приемлемые\" сроки. \n",
    "\n",
    "Попробуем оба варианта и посмотрим на длительность и результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала стемминг. А ещё более сначала - токенизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 604 ms, total: 1min 6s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def tokenizer(string):\n",
    "    return nltk.word_tokenize(string)\n",
    "    \n",
    "comment_tokenized = comment_data['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation',\n",
       " 'why',\n",
       " 'the',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'under',\n",
       " 'my',\n",
       " 'username',\n",
       " 'hardcore',\n",
       " 'metallica',\n",
       " 'fan',\n",
       " 'were',\n",
       " 'reverted',\n",
       " 'they',\n",
       " 'weren',\n",
       " 't',\n",
       " 'vandalisms',\n",
       " 'just',\n",
       " 'closure',\n",
       " 'on',\n",
       " 'some',\n",
       " 'gas',\n",
       " 'after',\n",
       " 'i',\n",
       " 'voted',\n",
       " 'at',\n",
       " 'new',\n",
       " 'york',\n",
       " 'dolls',\n",
       " 'fac',\n",
       " 'and',\n",
       " 'please',\n",
       " 'don',\n",
       " 't',\n",
       " 'remove',\n",
       " 'the',\n",
       " 'template',\n",
       " 'from',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " 'i',\n",
       " 'm',\n",
       " 'retired',\n",
       " 'now']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_tokenized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, среди \"разделенных слов\" явно видно наличие \"следов\" кривой предобработки - отдельностоящие буквы s, t, n и т.п. от разделенных don't, i'm и т.д. Да, косяк, Однако, полагаю, что для нашей задачи это не будет большой потерей, т.к. первоформа слов (насколько мне известно), не включает отрицание. Хотя, вероятно, я не прав. Посмотрим на результат стемминга и подумаем о перспективах. \n",
    "\n",
    "С другой стороны, полагаю, что слова-в-одну-букву не окажут особого влияния на смысл предложения. С третьей стороны, их существование максимум добавит 28 признаков, что в масштабе всего проекта - капля в море. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 ms, sys: 0 ns, total: 1.25 ms\n",
      "Wall time: 1.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stemmer = PorterStemmer()\n",
    "test_data = comment_tokenized[2]\n",
    "stemmer_output = ' '.join([stemmer.stem(w) for w in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 s, sys: 96 ms, total: 2.81 s\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый, очень важный пункт - на представленных данных Лемматайзер БЫСТРЕЕ стемера. Это хорошо. Сравним конечные результаты с исходным текстом по критерию \"адекватности\" перевода. Да, это чисто субъективно, однако, думаю, в этом смысле мы все будем близки к некоторому общему виду \"как должно быть\".\n",
    "\n",
    ">UPD. Спустя 2 запуска, стеммер \"стеммит\" быстрее. Хммм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'man', 'i', 'm', 'really', 'not', 'trying', 'to', 'edit', 'war', 'it', 's', 'just', 'that', 'this', 'guy', 'is', 'constantly', 'removing', 'relevant', 'information', 'and', 'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my', 'talk', 'page', 'he', 'seems', 'to', 'care', 'more', 'about', 'the', 'formatting', 'than', 'the', 'actual', 'info']\n",
      "\n",
      "hey man i m realli not tri to edit war it s just that thi guy is constantli remov relev inform and talk to me through edit instead of my talk page he seem to care more about the format than the actual info\n",
      "\n",
      "hey man i m really not trying to edit war it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info\n"
     ]
    }
   ],
   "source": [
    "print(test_data)\n",
    "print()\n",
    "print(stemmer_output)\n",
    "print()\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматайзер также показал себя лучше с точки зрения корректного извлечения слов. Да, не везде, однако \"косяки\" стеммера несравнимо больше, чем в случае лемм. Напишем функцию для лемматизации всего массива данных и оценим сроки выполнения этой части предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def data_lemmas(text):\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in text])\n",
    "    return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.3 s, sys: 228 ms, total: 55.5 s\n",
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "comment_lemmas = comment_tokenized.apply(data_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минута на лемматизацию - супер!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся значениями TF-IDF в качестве признков для модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 196 ms, total: 10.8 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(159571, 153504)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "comment_tf_idf = count_tf_idf.fit_transform(comment_lemmas)\n",
    "comment_tf_idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "160 тысяч на 160 тысяч значений. Причем не нулей и единиц, а флоатов - ведь tf-idf почти никогда не равен единице. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что датасет у нас готов. Нарежем его на обучающую, валидационную и тестовую части (60 к 20 к 20) и подберем несколько моделей для обучения и прогнозирования. Метрика по-прежнему F1.\n",
    "\n",
    "Такое распределение выбрал, т.к. планирую использовать гридсёрч и нужны будут обучающие + валидационные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Столкнулся сам + читал в слаке, что платформа практикума с большим скрипом тянула рассчеты по этому проекту. Не знаю, ребят, что вы сделали, но сейчас будто лечу в самолёте первым классом) Всё считается быстро) Спасибо вам!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95742, 153504)\n",
      "(31914, 153504)\n",
      "(31915, 153504)\n"
     ]
    }
   ],
   "source": [
    "features = comment_tf_idf\n",
    "target = comment_data['toxic']\n",
    "\n",
    "f_train_valid, f_test, t_train_valid, t_test = train_test_split(features, target, \n",
    "                                                                test_size = 0.2, random_state = 11111)\n",
    "f_train, f_valid, t_train, t_valid = train_test_split(f_train_valid, t_train_valid, \n",
    "                                                    test_size = 0.25, random_state = 11111)\n",
    "\n",
    "print(f_train.shape)\n",
    "print(f_valid.shape)\n",
    "print(f_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово. Переходим к подбору модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение и валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помня, что перед нами задача классификации, воспользуемся логистической регрессией и градиентными глупыми деревьями от Майкрософт (LGBM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва - лог.рег."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg = LogisticRegression(random_state = 11111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повлиять на качество модели мы можем с помощью балансировки классов. Но не с помощью up- и down-грейда датасета, а с помощью балансировки классов. \n",
    ">class_weight = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.48 s, sys: 3.88 s, total: 8.36 s\n",
      "Wall time: 8.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=11111, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_logreg.fit(f_train, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 секунд на обучение модели! Неплохо, очень неплохо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7020593236349896"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_predict = model_logreg.predict(f_valid)\n",
    "f1_score_logreg = f1_score(t_valid, logreg_predict)\n",
    "f1_score_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимально допустимое значение метрики - 0.75.\n",
    "\n",
    "Полученных 0.702 мало. Балансируем классы, переучиваем модель и смотрим на результат ещё раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7523887523887524"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logreg_balanced = LogisticRegression(random_state = 11111, class_weight = 'balanced')\n",
    "model_logreg_balanced.fit(f_train, t_train)\n",
    "logreg_balanced_predict = model_logreg_balanced.predict(f_valid)\n",
    "f1_score_logreg_balanced = f1_score(t_valid, logreg_balanced_predict)\n",
    "f1_score_logreg_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парам-парам-пам! Пам! Фьюф!\n",
    "\n",
    "Готово. Мы выше 0.75.\n",
    "\n",
    "В дополнение ко всему, мы помним про возможность нахождения гиперпараметров. Даже у логистической регрессии. Запустим гридсёрч (это мой первый раз) и посмотрим на \"лучший\" вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# это мы создаем \"матрицу\" варьирования значений регуляризации. \n",
    "# От 10 в -1 (0.1) до 10 в 1 (10). 3 значения на логарифмической шкале в этом диапазоне\n",
    "\n",
    "c_space = np.logspace(-1, 1, 3)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "model_logreg_gv = LogisticRegression(random_state = 11111)\n",
    "\n",
    "logreg_cv = GridSearchCV(model_logreg_gv, param_grid, cv = 4, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся специально заготовленным для этого случая датасета обучение+валидация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 1min 5s, total: 2min 11s\n",
      "Wall time: 2min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=11111, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([ 0.1,  1. , 10. ])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logreg_cv.fit(f_train_valid, t_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0}\n",
      "0.7612796752075379\n"
     ]
    }
   ],
   "source": [
    "print(logreg_cv.best_params_)\n",
    "print(logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В сравнении со стоковой моделью прирост почти в 0.06 для f1 - это весьма существено. \n",
    "Посмотрим, что можно получить для модели с балансировкой и регуляризацией. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0}\n",
      "0.7596579690404472\n",
      "CPU times: user 1min 40s, sys: 1min 47s, total: 3min 28s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_logreg_balanced_gv = LogisticRegression(random_state = 11111, class_weight = 'balanced')\n",
    "logreg_balanced_cv = GridSearchCV(model_logreg_balanced_gv, param_grid, cv = 4, scoring = 'f1')\n",
    "logreg_balanced_cv.fit(f_train_valid, t_train_valid)\n",
    "print(logreg_balanced_cv.best_params_)\n",
    "print(logreg_balanced_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прироста к аналогичной модели без балансировки почти нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Занесем полученные значения метрики и гиперпараметров в финальную таблицу и движемся дальше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.702059</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия с балансировкой</td>\n",
       "      <td>0.752389</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия с регуляризацией</td>\n",
       "      <td>0.761280</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Логистическая регрессия с балансировкой и регу...</td>\n",
       "      <td>0.759658</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model        f1   c\n",
       "0                            Логистическая регрессия  0.702059   -\n",
       "1            Логистическая регрессия с балансировкой  0.752389   -\n",
       "2           Логистическая регрессия с регуляризацией  0.761280  10\n",
       "3  Логистическая регрессия с балансировкой и регу...  0.759658  10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table = pd.DataFrame(data = [], columns = ['model','f1', 'c'])\n",
    "final_table.loc[0, 'model'] = 'Логистическая регрессия'\n",
    "final_table.loc[0, 'f1'] = f1_score_logreg\n",
    "\n",
    "final_table.loc[1, 'model'] = 'Логистическая регрессия с балансировкой'\n",
    "final_table.loc[1, 'f1'] = f1_score_logreg_balanced\n",
    "\n",
    "final_table.loc[2, 'model'] = 'Логистическая регрессия с регуляризацией'\n",
    "final_table.loc[2, 'f1'] = logreg_cv.best_score_\n",
    "final_table.loc[2, 'c'] = logreg_cv.best_params_['C']\n",
    "\n",
    "final_table.loc[3, 'model'] = 'Логистическая регрессия с балансировкой и регуляризацией'\n",
    "final_table.loc[3, 'f1'] = logreg_balanced_cv.best_score_\n",
    "final_table.loc[3, 'c'] = logreg_balanced_cv.best_params_['C']\n",
    "\n",
    "final_table = final_table.fillna('-')\n",
    "final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К градиентному бустингу.\n",
    "\n",
    "Разберемся с тем, какие гиперпараметры (и не только) нам следует взять для данной модели, чтобы она могла делать бинарную классификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(f_train, label = t_train, free_raw_data = False)\n",
    "valid_data = lgb.Dataset(f_valid, label = t_valid, free_raw_data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_gbdt = {'task' : 'train',\n",
    "                   'boosting_type' : 'gbdt',\n",
    "                   'objective' : 'binary',\n",
    "                   'metric' : ['binary_logloss'],\n",
    "                   'is_training_metric' : True,\n",
    "                   'max_bin' : 255,\n",
    "                   'learning_rate' : 0.05,\n",
    "                   'num_leaves' : 100\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's binary_logloss: 0.252872\n",
      "[10]\tvalid_0's binary_logloss: 0.220056\n",
      "[15]\tvalid_0's binary_logloss: 0.201091\n",
      "[20]\tvalid_0's binary_logloss: 0.188215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6367444643925793"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = lgb.train(parameters_gbdt, train_data, 20, valid_sets = valid_data, verbose_eval = 5)\n",
    "    \n",
    "pred_valid = best_model.predict(f_valid, num_iteration=best_model.best_iteration)\n",
    "\n",
    "pred_valid_real = pred_valid.round()\n",
    "f1_lgbm = f1_score(t_valid, pred_valid_real)\n",
    "f1_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики f1 в данной библиотеке не обнаружено, поэтому вычисляем её самостоятельно. Предсказания модели - не готовые классы, а вероятность класса \"1\" - того, что комментарий токсичен. Поэтому, округляем значения вероятностей до целого числа (верояность 0.5 и ниже - 0 класс, всё оставльное - 1 класс).\n",
    "\n",
    "> здесь кернел начал очень часто помирать. Не знаю, что сделать с этим. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, чего можно добиться, увеличив число итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's binary_logloss: 0.252872\n",
      "[10]\tvalid_0's binary_logloss: 0.220056\n",
      "[15]\tvalid_0's binary_logloss: 0.201091\n",
      "[20]\tvalid_0's binary_logloss: 0.188215\n",
      "[25]\tvalid_0's binary_logloss: 0.179254\n",
      "[30]\tvalid_0's binary_logloss: 0.171736\n",
      "[35]\tvalid_0's binary_logloss: 0.165547\n",
      "[40]\tvalid_0's binary_logloss: 0.159822\n",
      "[45]\tvalid_0's binary_logloss: 0.155136\n",
      "[50]\tvalid_0's binary_logloss: 0.150964\n",
      "[55]\tvalid_0's binary_logloss: 0.147632\n",
      "[60]\tvalid_0's binary_logloss: 0.144619\n",
      "[65]\tvalid_0's binary_logloss: 0.141988\n",
      "[70]\tvalid_0's binary_logloss: 0.139682\n",
      "[75]\tvalid_0's binary_logloss: 0.137507\n",
      "[80]\tvalid_0's binary_logloss: 0.13574\n",
      "[85]\tvalid_0's binary_logloss: 0.134283\n",
      "[90]\tvalid_0's binary_logloss: 0.132887\n",
      "[95]\tvalid_0's binary_logloss: 0.131736\n",
      "[100]\tvalid_0's binary_logloss: 0.130746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6367444643925793"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_100 = lgb.train(parameters_gbdt, train_data, 100, valid_sets = valid_data, verbose_eval = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7475386779184247"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid_100 = best_model_100.predict(f_valid, num_iteration=best_model.best_iteration)\n",
    "pred_valid_real_100 = pred_valid_100.round()\n",
    "f1_lgbm_100 = f1_score(t_valid, pred_valid_real_100)\n",
    "f1_lgbm_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Больше итераций - существенно больше и показатель f1-меры. Да, время обучения также возрастает существенно. Зафиксируем полученные данные в таблице и перейдем к тестированию полученных моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>c</th>\n",
       "      <th>num_iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.702059</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия с балансировкой</td>\n",
       "      <td>0.752389</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия с регуляризацией</td>\n",
       "      <td>0.761280</td>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Логистическая регрессия с балансировкой и регу...</td>\n",
       "      <td>0.759658</td>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Градиентный бустинг, 20 итераций</td>\n",
       "      <td>0.636744</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Градиентный бустинг, 100 итераций</td>\n",
       "      <td>0.747539</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model        f1   c  \\\n",
       "0                            Логистическая регрессия  0.702059   -   \n",
       "1            Логистическая регрессия с балансировкой  0.752389   -   \n",
       "2           Логистическая регрессия с регуляризацией  0.761280  10   \n",
       "3  Логистическая регрессия с балансировкой и регу...  0.759658  10   \n",
       "4                   Градиентный бустинг, 20 итераций  0.636744   -   \n",
       "5                  Градиентный бустинг, 100 итераций  0.747539   -   \n",
       "\n",
       "  num_iterations  \n",
       "0              -  \n",
       "1              -  \n",
       "2              -  \n",
       "3              -  \n",
       "4             20  \n",
       "5            100  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table.loc[4, 'model'] = 'Градиентный бустинг, 20 итераций'\n",
    "final_table.loc[4, 'f1'] = f1_lgbm\n",
    "final_table.loc[4, 'num_iterations'] = 20\n",
    "\n",
    "final_table.loc[5, 'model'] = 'Градиентный бустинг, 100 итераций'\n",
    "final_table.loc[5, 'f1'] = f1_lgbm_100\n",
    "final_table.loc[5, 'num_iterations'] = 100\n",
    "\n",
    "final_table = final_table.fillna('-')\n",
    "final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Тестирование и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.707102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model f1_score_test\n",
       "0  Логистическая регрессия      0.707102"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test_table = pd.DataFrame(data = [], columns = ['model', 'f1_score_test'])\n",
    "\n",
    "pred_test_logreg = model_logreg.predict(f_test)\n",
    "f1_test_table.loc[0, 'model'] = final_table.loc[0, 'model']\n",
    "f1_test_table.loc[0, 'f1_score_test'] = f1_score(t_test, pred_test_logreg)\n",
    "f1_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.707102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия с балансировкой</td>\n",
       "      <td>0.742416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model f1_score_test\n",
       "0                  Логистическая регрессия      0.707102\n",
       "1  Логистическая регрессия с балансировкой      0.742416"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_logreg_balanced = model_logreg_balanced.predict(f_test)\n",
    "\n",
    "f1_test_table.loc[1, 'model'] = final_table.loc[1, 'model']\n",
    "f1_test_table.loc[1, 'f1_score_test'] = f1_score(t_test, pred_test_logreg_balanced)\n",
    "f1_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.707102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия с балансировкой</td>\n",
       "      <td>0.742416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия с регуляризацией</td>\n",
       "      <td>0.775307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model f1_score_test\n",
       "0                   Логистическая регрессия      0.707102\n",
       "1   Логистическая регрессия с балансировкой      0.742416\n",
       "2  Логистическая регрессия с регуляризацией      0.775307"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logreg_gv = LogisticRegression(C = 10, random_state = 11111)\n",
    "model_logreg_gv.fit(f_train_valid, t_train_valid)\n",
    "\n",
    "pred_test_logreg_gv = model_logreg_gv.predict(f_test)\n",
    "\n",
    "f1_test_table.loc[2, 'model'] = final_table.loc[2, 'model']\n",
    "f1_test_table.loc[2, 'f1_score_test'] = f1_score(t_test, pred_test_logreg_gv)\n",
    "f1_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.707102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия с балансировкой</td>\n",
       "      <td>0.742416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия с регуляризацией</td>\n",
       "      <td>0.775307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Логистическая регрессия с балансировкой и регу...</td>\n",
       "      <td>0.763658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model f1_score_test\n",
       "0                            Логистическая регрессия      0.707102\n",
       "1            Логистическая регрессия с балансировкой      0.742416\n",
       "2           Логистическая регрессия с регуляризацией      0.775307\n",
       "3  Логистическая регрессия с балансировкой и регу...      0.763658"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logreg_gv_balanced = LogisticRegression(C = 10, class_weight = 'balanced', random_state = 11111)\n",
    "model_logreg_gv_balanced.fit(f_train_valid, t_train_valid)\n",
    "\n",
    "pred_test_logreg_gv_balanced = model_logreg_gv_balanced.predict(f_test)\n",
    "\n",
    "f1_test_table.loc[3, 'model'] = final_table.loc[3, 'model']\n",
    "f1_test_table.loc[3, 'f1_score_test'] = f1_score(t_test, pred_test_logreg_gv_balanced)\n",
    "f1_test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.707102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия с балансировкой</td>\n",
       "      <td>0.742416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия с регуляризацией</td>\n",
       "      <td>0.775307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Логистическая регрессия с балансировкой и регу...</td>\n",
       "      <td>0.763658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Градиентный бустинг, 20 итераций</td>\n",
       "      <td>0.637729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model f1_score_test\n",
       "0                            Логистическая регрессия      0.707102\n",
       "1            Логистическая регрессия с балансировкой      0.742416\n",
       "2           Логистическая регрессия с регуляризацией      0.775307\n",
       "3  Логистическая регрессия с балансировкой и регу...      0.763658\n",
       "4                   Градиентный бустинг, 20 итераций      0.637729"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gbdt_test = best_model.predict(f_test, num_iteration=best_model.best_iteration)\n",
    "f1_test_table.loc[4, 'model'] = final_table.loc[4, 'model']\n",
    "f1_test_table.loc[4, 'f1_score_test'] = f1_score(t_test, pred_gbdt_test.round())\n",
    "f1_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.707102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия с балансировкой</td>\n",
       "      <td>0.742416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия с регуляризацией</td>\n",
       "      <td>0.775307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Логистическая регрессия с балансировкой и регу...</td>\n",
       "      <td>0.763658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Градиентный бустинг, 20 итераций</td>\n",
       "      <td>0.637729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Градиентный бустинг, 100 итераций</td>\n",
       "      <td>0.750136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model f1_score_test\n",
       "0                            Логистическая регрессия      0.707102\n",
       "1            Логистическая регрессия с балансировкой      0.742416\n",
       "2           Логистическая регрессия с регуляризацией      0.775307\n",
       "3  Логистическая регрессия с балансировкой и регу...      0.763658\n",
       "4                   Градиентный бустинг, 20 итераций      0.637729\n",
       "5                  Градиентный бустинг, 100 итераций      0.750136"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gbdt_100_test = best_model_100.predict(f_test, num_iteration=best_model_100.best_iteration)\n",
    "f1_test_table.loc[5, 'model'] = final_table.loc[5, 'model']\n",
    "f1_test_table.loc[5, 'f1_score_test'] = f1_score(t_test, pred_gbdt_100_test.round())\n",
    "f1_test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удивительно, но факт. По итогу эксперимента, пороговое значение прошло сразу 3 модели из 6 - Их вы можете наблюдать в таблице ниже. Причем, что важно, в ряде случаев, точность модели даже увеличивалась по сравнению с значениями для валидационной выборки. \n",
    "\n",
    "В нашем случае логистическая регрессия c регуляризацией (С = 10) - топ 1 по значению f1 - метрики взвешенной точности и полноты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>f1_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия с регуляризацией</td>\n",
       "      <td>0.775307</td>\n",
       "      <td>0.761280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Логистическая регрессия с балансировкой и регу...</td>\n",
       "      <td>0.763658</td>\n",
       "      <td>0.759658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Градиентный бустинг, 100 итераций</td>\n",
       "      <td>0.750136</td>\n",
       "      <td>0.747539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия с балансировкой</td>\n",
       "      <td>0.742416</td>\n",
       "      <td>0.752389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.707102</td>\n",
       "      <td>0.702059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Градиентный бустинг, 20 итераций</td>\n",
       "      <td>0.637729</td>\n",
       "      <td>0.636744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model f1_score_test  f1_valid\n",
       "2           Логистическая регрессия с регуляризацией      0.775307  0.761280\n",
       "3  Логистическая регрессия с балансировкой и регу...      0.763658  0.759658\n",
       "5                  Градиентный бустинг, 100 итераций      0.750136  0.747539\n",
       "1            Логистическая регрессия с балансировкой      0.742416  0.752389\n",
       "0                            Логистическая регрессия      0.707102  0.702059\n",
       "4                   Градиентный бустинг, 20 итераций      0.637729  0.636744"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test_table['f1_valid'] = final_table['f1']\n",
    "f1_test_table.sort_values(by = 'f1_score_test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, в рамках проекта можно было получить ЛУЧШИЕ результаты - я точно это знаю и уверен, что приложив чуть больше усилий, я бы мог добиться большей точности за счёт:\n",
    "\n",
    "1) более качественной предобработки данных и извлечения признаков:\n",
    "- убрав одиночные буквы\n",
    "- воспользовавшишься иным способом создания признаков\n",
    "- оставив апострофы в нужных местах\n",
    "- воспользовавшись БЕРТом\n",
    "\n",
    "2) использования других моделей машинного обучения и настройки гиперпараметров существующих моделей.\n",
    "- в случае логистической регрессии стоило пройти более широкий диапазон значений C - с меньшим шагом. Это позволило бы ещё повысить значение f1, не \"сорвавшись\" при этом в \"пропасть переобучения\".\n",
    "- в случае градиентного бустинга - пройтись гридСёрчем по значениям скорости обучения, числа итераций, числа листьев, размера батча и т.д. И 100%, мы бы достигли лучшего и по времени и по точности значения f1-меры. \n",
    "\n",
    "Однако, в моей жизни происходит куча сложных моментов, которые мне тяжело вывозить психологически и у меня просто нет сил дальше \"прорабатывать\" этот проект.\n",
    "\n",
    "Спасибо вам за вашу работу!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
